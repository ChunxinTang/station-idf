{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load necessary libraries\n",
    "%matplotlib inline\n",
    "from constructIDF import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['xtick.labelsize'] = 14\n",
    "rcParams['ytick.labelsize'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read file with daily rainfall from downscaled GCM ouput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1: Specify path to hourly rainfall time series\n",
    "\n",
    "Specify the path to where you downloaded the historical downscaled GCM data in the cell below, between quotation marks. The standard path looks like: \"/users/user/documents/cmu/rainfall/maca_hist.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"[*]\"\n",
    "\n",
    "hist_gcm_path = \"\"\n",
    "hist_gcm_data = pd.read_csv(historical_path, skiprows=26, parse_dates=[\"yyyy-mm-dd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Construct Annual Maximum Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1: Reformat data to functions' required input format\n",
    "We need to reformat the data to the required format by the library `constructIDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_gcm_data['year'] = hist_gcm_data[\"yyyy-mm-dd\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2: Extract Annual Maximum Series\n",
    "\n",
    "hist_gcm_ams is the variable where we store the annual maxima (the line of code in the following cell extracts the maximum daily rainfall each year over the historical period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_gcm_ams = hist_gcm_data.groupby(pd.Grouper(key=\"yyyy-mm-dd\", freq='A')).max()\n",
    "\n",
    "cols = list(hist_gcm_ams)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "hist_gcm_ams = hist_gcm_ams.loc[:, cols]\n",
    "\n",
    "hist_gcm_ams = hist_gcm_ams.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3: Take a look at the AMS output table\n",
    "\n",
    "The table below correspond to the annual maxima each year (row) and downscaled GCM (column) from MACA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#########################\n",
    "#                       # \n",
    "#   Historical Model    #\n",
    "#      AMS TABLE        #\n",
    "#                       #\n",
    "#########################\n",
    "\n",
    "hist_gcm_ams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fit Generalized Extreme Value and obtain precipitation estimates (inches or mm) by average recurrence interval (ARI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to fit a generalized extreme value distribution to each duration's AMS. Once the parameters (location, scale and shape) are estimated, these are used to retrieve the return levels (in this case, rainfall depth) for different quantiles feed into the inverse of the CDF. Usually, the quantiles are equal to the inverse of the average recurrence interval (ARI) (e.g. 1/2 = 2-year).\n",
    "\n",
    "`constructIDF` has one method that merges all these steps, but we need to specify if we want to construct confidence intervals. The method implemented in `constructIDF` is bootstrapping, so we also need to specify the number of bootsrapped samples. Default value is 1000, and using a smaller number is not recommended.\n",
    "\n",
    "Other specification is the confidence level, alpha, used to estimate the confidence intervals. Default is 0.9 (90% confidence interval).\n",
    "\n",
    "\n",
    "In this tutorial, we will compute confidence intervals at a 90% confidence level using 1000 bootstrapped samples.\n",
    "\n",
    "```python\n",
    "ci = True\n",
    "alpha = 0.9\n",
    "number_bootstrap = 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.1: Specify values for IDF function and run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = True\n",
    "alpha = 0.9\n",
    "number_bootstrap = 100\n",
    "\n",
    "hist_gcm_idf = IDF(hist_gcm_ams, ci, number_bootstrap, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Step 3.2: Construct IDF from the function IDF output.\n",
    "\n",
    "Note: This will take long time because of the number of bootstrapped samples. The constructed IDF is by default for the following ARI: 2-, 5-, 10-, 25-, 50-, 100-, 200-year. Some errors will be displayed, no worries. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_gcm_idf.construct_IDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.3: Access the IDF table\n",
    "\n",
    "We can access the table with the precipitation estimate values\n",
    "for each return period and the corresponding 90% CI confidence bounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "#                                    # \n",
    "#             IDF TABLE              #\n",
    "#       Historical (1950-2005)       #\n",
    "#                                    #\n",
    "######################################\n",
    "\n",
    "\n",
    "hist_gcm_idf.idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Repeat the process, but now using future data as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"[*]\"\n",
    "\n",
    "\"\"\"\n",
    "Specify here the path to the precipitation data corresponding to the future period.\n",
    "\"\"\"\n",
    "fut_gcm_path = \"\"\n",
    "fut_gcm_data = pd.read_csv(fut_gcm_path, skiprows=26, parse_dates=[\"yyyy-mm-dd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1: Reformat data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut_gcm_data['year'] = fut_gcm_data[\"yyyy-mm-dd\"].dt.year\n",
    "fut_gcm_ams = fut_gcm_data.groupby(pd.Grouper(key=\"yyyy-mm-dd\", freq='A')).max()\n",
    "\n",
    "\n",
    "\n",
    "cols = list(fut_gcm_ams)\n",
    "cols.insert(0, cols.pop(cols.index('year')))\n",
    "fut_gcm_ams = fut_gcm_ams.loc[:, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.2: Filter the AMS series to select a period that matches the historical period length. In other words, if we have 56 years of annual maxima in the period 1950-2005, we need to select a future period that spans the same number of years. In this case, 2043-2099.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut_gcm_ams = fut_gcm_ams['2043':'2099']\n",
    "fut_gcm_ams = fut_gcm_ams.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "#                       #\n",
    "#      Future Model     #\n",
    "#       AMS TABLE       #\n",
    "#                       #\n",
    "#########################\n",
    "\n",
    "fut_gcm_ams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.3: Input the future AMS and the same specifications when we calculated the historical gcm IDF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut_gcm_idf = IDF(fut_gcm_ams, ci, number_bootstrap, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.4: Construct IDF from the data we feed above and our specifications. \n",
    "\n",
    "Some errors will be displayed, no worries. This will take long time because of the number of bootsrapped samples. The constructed IDF is by default for the following ARI: 2-, 5-, 10-, 25-, 50-, 100-, 200-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut_gcm_idf.construct_IDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.5: Take a look at the future GCM idf values.\n",
    "\n",
    "**Note** that we no longer have *durations* by column. \n",
    "We are focusing on the 24h. Now, each column corresponds to the 24h future idf GCM precipitation estimate for each return period and confidence bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "#                                    # \n",
    "#          Future Model              #\n",
    "#           IDF TABLE                #\n",
    "#                                    #\n",
    "######################################\n",
    "\n",
    "fut_gcm_idf.idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Find the precipitation estimate change factor by return period using the delta-change method\n",
    "\n",
    "The change factor is equal to the ratio between historical IDF values and future IDF values (both estimated using the downscaled GCM data which is what we have been doing in the previous steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_factors = pd.DataFrame(fut_gcm_idf.idf.values/hist_gcm_idf.idf.values)\n",
    "\n",
    "# Reformat table for better presentation\n",
    "change_factors.columns = [x.rstrip(\"_rcp85(mm)\") for x in fut_gcm_idf.idf.columns]\n",
    "change_factors['return_period'] = fut_gcm_idf.idf.index\n",
    "change_factors.set_index('return_period', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "#                                  # \n",
    "#          CHANGE FACTORS          #\n",
    "#             TABLE                #\n",
    "#                                  #\n",
    "####################################\n",
    "\n",
    "change_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Update historical (station) IDF curves using change factor estimated in previous steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct a future IDF by updating the historical curve using the change factor that we estimated from the downscaled projections. \n",
    "\n",
    "Note that there are two options here:\n",
    "\n",
    "1. Assume equal change in all storm durations to the estimated change in the 24h rainfall depth (the change factors we computed above). \n",
    "2. Update the 24h only as we computed a change factor using daily downscaled GCM output\n",
    "\n",
    "In this exercise, we will choose option 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.1: Load idf values (CSV) from station IDF curve (24h)\n",
    "\n",
    "Insert the path to your data between the quotation marks in the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"[*]\"\n",
    "\n",
    "hist_station_idf = pd.read_csv(\"\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.2: Multiply the station 24h IDF curve (`hist_station_idf`) by change factor table (`change_factors`)\n",
    "\n",
    "The code below is multiplying the station 24h curve values\n",
    "with the change factors table computed in the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#                                    # \n",
    "#         Station Future             #\n",
    "#           IDF TABLE                #\n",
    "#                                    #\n",
    "######################################\n",
    "\n",
    "fut_station_idf = change_factors.multiply(hist_station_idf[\"24H\"], axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6.3: Take a look at the updated station IDF values (now co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut_station_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Save the table above and plot updated station IDF curves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.1: Store table in CSV or compute statistics in this notebook\n",
    "\n",
    "The `fut_station_idf` correspond to the station future 24h precipitation estimate projected by each GCM.\n",
    "You can perform ensemble statistics (take the mean, median or quantiles across the GCMs) to get a sense of\n",
    "what the future 24h precipitation value at the station will be given the projected values from the GCMs.\n",
    "\n",
    "You can save the table stored in the variable `fut_station_idf` to a CSV using pandas. The line of code will look like (you need to replace the `path/to/csv` portion to your desired save location):\n",
    "\n",
    "`fut_station_idf.to_csv(\"path/to/csv/fut_station_idf.csv\")` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7.2: Plot idf curves for each GCM model\n",
    "\n",
    "We can call the `plot_IDF` method to create the IDF curves and plot them.\n",
    "We need to specify a path where to store the figure, as well as the figure format.\n",
    "\n",
    "Specify in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"[*]\"\n",
    "\n",
    "figure_path = \".\"\n",
    "figure_name = \"fut_station_idf_plot\"\n",
    "figure_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_idf_transposed = fut_station_idf.transpose()\n",
    "dfmean = station_idf_transposed.drop([x for x in station_idf_transposed.columns if (\n",
    "                x[:1] == 'L' or x[:1] == 'U')], axis=1)\n",
    "\n",
    "dfmean = dfmean.transpose()\n",
    "fig, axs = plt.subplots(figsize=(13, 10))\n",
    "a1 = dfmean.plot(ax=axs)\n",
    "fill_alpha = 0.3\n",
    "\n",
    "legend = plt.legend(title='GCM Model', fontsize=13)\n",
    "plt.setp(legend.get_title(), fontsize=15)\n",
    "plt.ylabel('Precipitation Depth (mm)', {'fontsize': 18})\n",
    "plt.xlabel('Return Period', {'fontsize': 18})\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"{}/{}.{}\".format(figure_path, figure_name, figure_format), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
